{"cells":[{"cell_type":"code","metadata":{"id":"wbvMlHd_QwMG"},"source":["#Yolov5 import block\n","!git clone https://github.com/ultralytics/yolov5  # clone\n","%cd yolov5\n","%pip install -qr requirements.txt comet_ml  # install\n","\n","!pip install ultralytics comet_ml torch torchvision\n","\n","import torch\n","import utils\n","display = utils.notebook_init()  # checks"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# comet data visualiser import\n","from comet_ml import Experiment\n","from comet_ml.integration.pytorch import log_model\n","\n","experiment = Experiment(\n","  api_key=\"P0NktKaxzEm8SHi2EhaLsV2FK\",\n","  project_name=\"leaf-area\",\n","  workspace=\"laaspere\"\n",")"],"metadata":{"id":"xMlrtgoa1OjY"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"85pNUB44kJez"},"outputs":[],"source":["#import block\n","import tensorflow as tf\n","from tensorflow import keras\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import cv2\n","import torch\n","import torchvision\n","import torch.onnx\n","from torchsummary import summary\n"]},{"cell_type":"code","source":["#for importing labelled dataset for RoboFlow\n","\n","!pip install roboflow\n","\n","from roboflow import Roboflow\n","rf = Roboflow(api_key=\"V63SFc2oAj7ZwbYLIgox\")\n","project = rf.workspace(\"leafareaproject\").project(\"leaf-area\")\n","version = project.version(4)\n","dataset = version.download(\"yolov5\")\n","\n","\n","\n"],"metadata":{"id":"1muAkKV4wc-5","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1712154722345,"user_tz":-180,"elapsed":35855,"user":{"displayName":"Lauri Laaspere","userId":"02936867058259187032"}},"outputId":"80824a35-8d35-4003-87e6-1e1b1f017a82"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting roboflow\n","  Downloading roboflow-1.1.26-py3-none-any.whl (71 kB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting certifi==2023.7.22 (from roboflow)\n","  Downloading certifi-2023.7.22-py3-none-any.whl (158 kB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m158.3/158.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting chardet==4.0.0 (from roboflow)\n","  Downloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m178.7/178.7 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting cycler==0.10.0 (from roboflow)\n","  Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n","Collecting idna==2.10 (from roboflow)\n","  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.4.5)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from roboflow) (3.7.1)\n","Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.25.2)\n","Collecting opencv-python-headless==4.8.0.74 (from roboflow)\n","  Downloading opencv_python_headless-4.8.0.74-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.1 MB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m49.1/49.1 MB\u001b[0m \u001b[31m915.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from roboflow) (9.4.0)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.8.2)\n","Collecting python-dotenv (from roboflow)\n","  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.31.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.16.0)\n","Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.0.7)\n","Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.66.2)\n","Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (6.0.1)\n","Collecting requests-toolbelt (from roboflow)\n","  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting python-magic (from roboflow)\n","  Downloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (1.2.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (4.50.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (24.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (3.1.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->roboflow) (3.3.2)\n","Installing collected packages: python-magic, python-dotenv, opencv-python-headless, idna, cycler, chardet, certifi, requests-toolbelt, roboflow\n","  Attempting uninstall: opencv-python-headless\n","    Found existing installation: opencv-python-headless 4.9.0.80\n","    Uninstalling opencv-python-headless-4.9.0.80:\n","      Successfully uninstalled opencv-python-headless-4.9.0.80\n","  Attempting uninstall: idna\n","    Found existing installation: idna 3.6\n","    Uninstalling idna-3.6:\n","      Successfully uninstalled idna-3.6\n","  Attempting uninstall: cycler\n","    Found existing installation: cycler 0.12.1\n","    Uninstalling cycler-0.12.1:\n","      Successfully uninstalled cycler-0.12.1\n","  Attempting uninstall: chardet\n","    Found existing installation: chardet 5.2.0\n","    Uninstalling chardet-5.2.0:\n","      Successfully uninstalled chardet-5.2.0\n","  Attempting uninstall: certifi\n","    Found existing installation: certifi 2024.2.2\n","    Uninstalling certifi-2024.2.2:\n","      Successfully uninstalled certifi-2024.2.2\n","Successfully installed certifi-2023.7.22 chardet-4.0.0 cycler-0.10.0 idna-2.10 opencv-python-headless-4.8.0.74 python-dotenv-1.0.1 python-magic-0.4.27 requests-toolbelt-1.0.0 roboflow-1.1.26\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["certifi","cycler"]},"id":"bcdd813fe8974fa9a3c33c67c6e90a16"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["loading Roboflow workspace...\n","loading Roboflow project...\n"]},{"output_type":"stream","name":"stderr","text":["Downloading Dataset Version Zip in Leaf-area-4 to yolov5pytorch:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6214/6214 [00:00<00:00, 68489.86it/s]"]},{"output_type":"stream","name":"stdout","text":["\n"]},{"output_type":"stream","name":"stderr","text":["\n","Extracting Dataset Version Zip to Leaf-area-4 in yolov5pytorch:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 273/273 [00:00<00:00, 7415.47it/s]\n"]}]},{"cell_type":"code","source":["#training\n","!export COMET_API_KEY=\"P0NktKaxzEm8SHi2EhaLsV2FK\"  # 2. paste API key\n","%cd yolov5\n","!python train.py --img 640 --epochs 100 --data '/content/yolov5/Leaf-area-4/data.yaml' --weights yolov5l.pt --cache --save-period 100\n"],"metadata":{"id":"4rvMV1K_w4QC"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zR9ZbuQCH7FX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712042662604,"user_tz":-180,"elapsed":10410,"user":{"displayName":"Lauri Laaspere","userId":"02936867058259187032"}},"outputId":"4cf2d14e-4cb6-401d-95b9-b7af1f7a2a07"},"source":["#detection\n","!python detect.py --weights /content/yolov5/runs/train/exp/weights/best.pt --img 640 --conf 0.25 --source '/content/AMF107.jpg'\n","#display.Image(filename='runs/detect/exp3/AMF001.jpg', width=600)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/yolov5/runs/train/exp/weights/best.pt'], source=/content/AMF107.jpg, data=data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_csv=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n","YOLOv5 ðŸš€ v7.0-295-gac6c4383 Python-3.10.12 torch-2.2.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n","\n","Fusing layers... \n","Model summary: 267 layers, 46113663 parameters, 0 gradients, 107.7 GFLOPs\n","WARNING âš ï¸ NMS time limit 0.550s exceeded\n","image 1/1 /content/AMF107.jpg: 640x480 1 control square, 10 leafs, 64.1ms\n","Speed: 0.6ms pre-process, 64.1ms inference, 592.0ms NMS per image at shape (1, 3, 640, 640)\n","Results saved to \u001b[1mruns/detect/exp\u001b[0m\n"]}]},{"cell_type":"markdown","source":["Older tests and stuff"],"metadata":{"id":"4veGB_8EPjBy"}},{"cell_type":"code","source":["#for loading TIFF images from Google drive\n","img = cv2.imread('/content/drive/MyDrive/Computational imaging/AMFexp_leafscans/AMF001.tif', cv2.IMREAD_GRAYSCALE)\n","rgb_img = cv2.merge([img, img, img])\n","print(rgb_img.shape)\n","plt.imshow(rgb_img)\n"],"metadata":{"id":"SDofx3eHfCI0"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NG-q7R2E0Zhv"},"outputs":[],"source":["!pip install ultralyticsplus==0.0.28 ultralytics==8.0.43\n","!pip install -U onnx\n","!pip install -U onnx-tf\n","!pip install tf2onnx"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nOFMeHUBXH2u"},"outputs":[],"source":["#Copying original pytorch library and saving it as ONNX format\n","\n","from ultralyticsplus import YOLO\n","\n","!git lfs install\n","!git clone https://huggingface.co/foduucom/plant-leaf-detection-and-classification\n","\n","model = YOLO('/content/plant-leaf-detection-and-classification/best.pt')\n","model.overrides['conf'] = 0.25  # NMS confidence threshold\n","model.overrides['iou'] = 0.45  # NMS IoU threshold\n","model.overrides['agnostic_nms'] = False  # NMS class-agnostic\n","model.overrides['max_det'] = 1000  # maximum number of detections per image\n","\n","model.export(format='onnx')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yTkZyiZLmRZk"},"outputs":[],"source":["#https://pypi.org/project/onnx2tf/ for converting ONNX to tensorflow\n","#This cell needs session restart but keeps the files\n","!sudo apt-get -y update\n","!sudo apt-get -y install python3-pip\n","!sudo apt-get -y install python-is-python3\n","!wget https://github.com/PINTO0309/onnx2tf/releases/download/1.16.31/flatc.tar.gz \\\n","  && tar -zxvf flatc.tar.gz \\\n","  && sudo chmod +x flatc \\\n","  && sudo mv flatc /usr/bin/\n","!pip install -U pip \\\n","  && pip install tensorflow==2.15.0 \\\n","  && pip install -U onnx==1.15.0 \\\n","  && python -m pip install onnx_graphsurgeon \\\n","        --index-url https://pypi.ngc.nvidia.com \\\n","  && pip install -U onnxruntime==1.16.3 \\\n","  && pip install -U onnxsim==0.4.33 \\\n","  && pip install -U simple_onnx_processing_tools \\\n","  && pip install -U onnx2tf \\\n","  && pip install -U protobuf==3.20.3 \\\n","  && pip install -U h5py==3.7.0 \\\n","  && pip install -U psutil==5.9.5 \\\n","  && pip install -U ml_dtypes==0.2.0\n","\n","#!onnx2tf -i /content/best.onnx -osd #saved_model with signaturedefs added.\n","!onnx2tf -i /content/plant-leaf-detection-and-classification/best.onnx -oh5 #Keras h5 format\n","!zip -r /content/saved_models.zip /content/saved_model #zipping for download"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jNy-t_Z2GIeJ"},"outputs":[],"source":["img = tiff.imread('/content/drive/MyDrive/Computational imaging/AMFexp_leafscans/AMF001.tif')\n","\n","model = tf.keras.models.load_model('/content/drive/MyDrive/Computational imaging/best_float32.keras')\n","#model.summary()\n","#tf.keras.utils.plot_model(model, show_shapes=True)"]},{"cell_type":"code","source":["#tf.keras.utils.plot_model(model)\n","img = cv2.imread('/content/drive/MyDrive/Computational imaging/AMFexp_leafscans/AMF001.tif', cv2.IMREAD_GRAYSCALE)\n","rgb_img = cv2.merge([img, img, img])\n","print(rgb_img.shape)\n","plt.imshow(rgb_img)\n","\n","model.compile(\n","  optimizer='adam',\n","  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","  metrics=['accuracy'])\n","\n","def preprocess_image(image, target_size=(640, 640)):\n","    # Resize the image\n","    image = tf.image.resize(image, target_size)\n","    # Normalize the pixel values to be in the range [0, 1]\n","    image = tf.cast(image, tf.float32) / 255.0\n","    return image\n","\n","# Path to the image file\n","image_path = img\n","\n","# Preprocess the image\n","preprocessed_image = preprocess_image(image_path)\n","model.evaluate(preprocessed_image)"],"metadata":{"id":"G9oIcVHF1VVi"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1LdaOtkno7gbL2BpNI5eUvpNS2nAHZ0bu","authorship_tag":"ABX9TyOMelg492bfC+VQ4WdntBbg"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}